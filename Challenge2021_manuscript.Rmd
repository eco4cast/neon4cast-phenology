---
title: "EFI NEON Phenology forecasting challenge"
author: "EFI NEON Phenology working group (Primarily Kathryn Wheeler and Michael Dietze)"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(scales)
library(colorBlindness)
library(dplyr)
library(ggplot2)
library(pals)
library(tidyverse)
library(tools)
library(mgcv)
library(ggridges)
library(gridExtra)
library(RColorBrewer)
library(ggthemes)
```

This script includes the code for the analyses and figure making for the manuscript analyzing the 2021 spring phenology forecast challenge: Predicting spring phenology in deciduous broadleaf forests: An open community forecast challenge

Forecasts should be downloaded from the google drive: gcc_forecast_subset_20220415.RData on  https://drive.google.com/drive/folders/10ckh3-PDtNzHnUyPTvUmTqARgdarl32f

Some figures were further edited outside of R for aesthetics. 

##General Variables
```{r}
teams <- c("PhenoPhriends", "PEG_RFR2","CU_Pheno","EFI_U_P","VT_Ph_GDD",
                 "CSP_Gwave","greenbears_par","PEG_RFR0","PEG_RFR","greenbears_gams",
                 "greenbears_stl","DALEC_SIP","PEG","Fourier",
                 "Team_MODIS","Persistence","GPEDM","DOY_Mean")
n_teams <- length(teams)

cls <- as.character(alphabet()[-c(5,8,16,17,21,24,26)]) #Team colors 
clsCopy <- cls
cls[14] <- clsCopy[18]
cls[18] <- clsCopy[14]
cls[9] <- clsCopy[6]
cls[6] <- clsCopy[9]
cls[17] <- cls[16]
cls[16] <- "#7570b3" #Want persistance to match class color 
cls <- cls[1:n_teams]
teamCls <- setNames(cls,teams)

site_names <- c("HARV", "BART", "SCBI", "STEI", "UKFS", "GRSM", "DELA", "CLBJ")
site_full_names <- c("Harvard","Bartlett","Smithsonian",
                     "Steigerwaldt","U. Kansas","Great Smokies",
                     "Dead Lake","Lyndon B. Johnson")
siteColors <- brewer.pal(name="Accent", n = 8)
siteColors[4] <- "cyan"
siteColors <- setNames(siteColors,site_names)

site_full_names <- setNames(site_full_names,site_names)
n_sites <- length(site_names)
siteLats <- c(42.537,44.0639,38.893,45.509,39.040,35.689,32.542,33.401)
siteMATs <- c(7.15,6.1,11.8,4.95,12.65,12.65,17.9,17.65)
siteLongs <- c(-72.173,-71.287,-78.140,-89.586,-95.192,-83.502,
               -87.804,-97.570)

classCls <- c("#1b9e77","#d95f02","#7570b3","#e7298a","#FF0010")
classCls <- setNames(classCls,c("covariate","dynamic","persist","static","clim"))
mtype <- c("TRUEFALSE","TRUETRUE","FALSETRUE",'FALSEFALSE','clim')
mtype <- setNames(mtype,c("covariate","dynamic","persist","static","clim"))
figureDirectory <- "manuscriptFigures/"


if(!dir.exists(figureDirectory)){
  dir.create(figureDirectory)
}
```

##Site Location Map with NPN Spring Anomaly. To grab the si-x_leaf_anomaly_historic.tif file of the Historical Annual Spring Indices Anomaly (2021), First Leaf - Spring Index go to https://www.usanpn.org/geoserver-request-builder and select the WCS service type and GeoTiff formats. 
```{r,eval=FALSE}
library(raster)
library(rgdal)
library(RColorBrewer)

NPN_anomaly <- raster('si-x_leaf_anomaly_historic.tif')
siteData <- as.data.frame(cbind(siteLats,siteLongs))
colnames(siteData) <- c("Latitude","Longitude")
coordinates(siteData) <- c("Longitude","Latitude")

proj4string(siteData) <- CRS("+proj=longlat +ellps=GRS80 +datum=NAD83")

jpeg(file=paste0(figureDirectory,"siteMap_withAnomaly.jpg"),height=5,width=7,units="in",res=1000)
plot(NPN_anomaly,col=brewer.pal(10,'RdYlGn'),bty="n")
#points(siteData, pch=16, col="red", cex=1)
points(siteData, col="black", pch=20)
text(siteData,labels=site_names,pos=2,offset=0.3)
dev.off()

```

##Grab Forecasts and Organize Data
Forecasts should be downloaded from the google drive: gcc_forecast_subset_20220415.RData on  https://drive.google.com/drive/folders/10ckh3-PDtNzHnUyPTvUmTqARgdarl32f

Note: The code that we used to download the forecasts from the AWS server is included below for completeness, but we cannot guarantee that this code will work or reproduce results when used as the server access changes. 

```{r,echo=FALSE}
if(file.exists('gcc_forecast_subset_20220415.RData')){
  load('gcc_forecast_subset_20220415.RData') 
  #Contains objects:
  ##allTransitions
  ##gcc_forecast_subset
  ##gcc_forecast_subset2
  ##gcc_forecast_subset3
  ##meta 
}else{ 
  ## grab and load forecast (updated based on Slack code snippet from Quinn)
  remotes::install_github("eco4cast/neon4cast")
  s <- neon4cast::score_schema() 
  s3 <- arrow::s3_bucket(bucket = "scores",
                         endpoint_override = "data.ecoforecast.org",
                         anonymous=TRUE)
  ds <- arrow::open_dataset(s3, schema=s, format = "csv", skip_rows = 1)
  submittedForecasts <- ds %>% filter(theme == "phenology", target=="gcc_90",
                                      forecast_start_time < lubridate::as_date("2021-06-30")) %>% collect()
  gccForecastsALL <- subset(submittedForecasts, target == "gcc_90")
  gccForecasts <- subset(gccForecastsALL,team %in% teams) #Subset to only include the teams that submitted spring forecasts and not the ones that joined for autumn 
  
  gcc_forecast_subset <- gccForecasts %>% 
    dplyr::filter(!is.na(mean) & 
                    horizon >= 1 & horizon <= 35 &
                    forecast_start_time >= lubridate::ymd("2021-02-01") & 
                    forecast_start_time <= lubridate::ymd("2021-06-01"))
  
  gcc_forecast_subset %>%
    dplyr::group_by(team) %>% 
    summarize(n = n()) %>% 
    dplyr::arrange(n) %>% 
    ggplot() + geom_point(aes(team, n)) + coord_flip() + theme_bw() + scale_y_log10()
  
  gcc_forecast_subset %>%
    group_by(forecast_start_time) %>% 
    summarize(n = n()) %>% 
    dplyr::arrange(n) %>% 
    ggplot() + geom_point(aes(forecast_start_time, n)) + theme_bw()
  
  transDateFile <- "allPhenologyTransitionData.csv"
  if(!file.exists(transDateFile)){
    source("calculatePhenoCamTransitionDates.R")
  }
  allTransitions <- readr::read_csv(transDateFile, col_names = TRUE)
}

gcc_forecast_subset <- gcc_forecast_subset %>% mutate(team=replace(team,team=="climatology","DOY_Mean")) %>% mutate(team=replace(team,team=="EFInull","Persistence")) %>%
mutate(team=replace(team,team=="UCSC_P_EDM","GPEDM"))

gcc_forecast_subset2 <- gcc_forecast_subset2 %>% mutate(team=replace(team,team=="climatology","DOY_Mean")) %>% mutate(team=replace(team,team=="EFInull","Persistence")) %>%
mutate(team=replace(team,team=="UCSC_P_EDM","GPEDM"))

gcc_forecast_subset3 <- gcc_forecast_subset3 %>% mutate(team=replace(team,team=="climatology","DOY_Mean")) %>% mutate(team=replace(team,team=="EFInull","Persistence")) %>%
mutate(team=replace(team,team=="UCSC_P_EDM","GPEDM"))
```

## Figure 2: The specific days that each modeling team forecasted (first plot) and the days that each team submitted forecasts on (second plot). The period where at least one site was between 15% and 85% greenup is indicated with green shading. 
```{r, echo=FALSE,fig.height=8, fig.width=6}
tranDates <- as.Date(unlist(allTransitions[,2]),origin=as.Date("2020-12-31"))
tranDates <- c(tranDates,as.Date(unlist(allTransitions[,8]),origin=as.Date("2020-12-31")))
challengeDays <- seq(as.Date("2021-02-01"),as.Date("2021-06-30"),"day")

# jpeg(file=paste0(figureDirectory,"DatesOfForecastAndSubmissionFigure.jpg"),width = 1000, height = 480, units = "px",res=1000)#,height=3,width=10,units="inch",res=700)

jpeg(file=paste0(figureDirectory,"DatesOfForecastAndSubmissionFigure.jpg"),height=5,width=10,units="in",res=1000)
par(mfrow=c(1,2),mai=c(1,2,0.3,0.1))
site_number <- 1 #Harvard example
#for(s in 1:length(site_names)){
gccForecastsYes <- data.frame(matrix(ncol=n_teams,nrow=length(challengeDays)))
teamOrder <- rev(c(18,16,17,15,14,13,9,8,2,12,11,10,7,1,6,5,4,3))
for(tm in 1:n_teams){
  tmDat <- gcc_forecast_subset[gcc_forecast_subset$team==teams[tm],] #Subset by team
  tmSitDat <- tmDat[tmDat$siteID==site_names[site_number],] #Subset by site
  uniqueTimes <- unique(as.Date(tmSitDat$time))
  for(d in 1:length(challengeDays)){
    gccForecastsYes[d,tm] <- challengeDays[d] %in% uniqueTimes
  }
}

colnames(gccForecastsYes) <- teams

#Plot first team and then add on subsequent teams onto the graph
tm <- 18
gccForecastsYes <- gccForecastsYes[,teamOrder]
plot(challengeDays[gccForecastsYes[,tm]],rep(tm,length(challengeDays))[gccForecastsYes[,tm]],pch=20,
     xlab="Date",ylab="",ylim=c(0,n_teams),bty="n",yaxt="n",main="",font.main=1)
title("a) Forecasted Dates", adj = 0)
axis(side = 2,at=seq(1,n_teams),labels=teams[teamOrder],pos=as.Date("2021-01-20"),las=1)

polygon(x=c(min(tranDates),min(tranDates),max(tranDates),max(tranDates)),y=c(-0.9,n_teams+1,n_teams+1,-0.9),col="gray",border=NA)
for(tm in 1:n_teams){
  points(challengeDays[gccForecastsYes[,tm]],rep(tm,length(challengeDays))[gccForecastsYes[,tm]],pch=20)
}

#Plot dates of submissions 
gccForecastsYes <- data.frame(matrix(ncol=n_teams,nrow=length(challengeDays)))

for(tm in 1:n_teams){
  tmDat <- gcc_forecast_subset[gcc_forecast_subset$team==teams[tm],] #Subset by team
  tmSitDat <- tmDat[tmDat$siteID==site_names[site_number],] #Subset by site

  uniqueTimes <- unique(as.Date(tmSitDat$start_time))
  for(d in 1:length(challengeDays)){
    gccForecastsYes[d,tm] <- challengeDays[d] %in% uniqueTimes
  }
}
colnames(gccForecastsYes) <- teams

tm <- 18
par(mai=c(1,0.1,0.3,2))
gccForecastsYes <- gccForecastsYes[,teamOrder]
plot(challengeDays[gccForecastsYes[,tm]],rep(tm,length(challengeDays))[gccForecastsYes[,tm]],pch=20,
     xlab="Date",ylab="",ylim=c(0,n_teams),bty="n",yaxt="n",main="",xlim=range(challengeDays),font.main=1)
title("b) Submission Dates", adj = 0)

polygon(x=c(min(tranDates),min(tranDates),max(tranDates),max(tranDates)),y=c(-0.9,n_teams+1,n_teams+1,-0.9),col="gray",border=NA)
for(tm in 1:n_teams){
  points(challengeDays[gccForecastsYes[,tm]],rep(tm,length(challengeDays))[gccForecastsYes[,tm]],pch=20)
}
dev.off()
```

##Supplementary Figure S1 and S2
```{r, echo=FALSE}
#Bar plot of the number of submissions per team
barDat <- gcc_forecast_subset %>% group_by(team) %>% summarise(n=n())

jpeg(file=paste0(figureDirectory,"numberOfSubmissionsPerTeam.jpg"),height=4,width=7,units="in",res=1000)
ggplot(barDat, aes(y=log(n),x=fct_reorder(team,n))) +
  geom_bar(position="dodge", stat="identity",color="grey31") +
  ggthemes::theme_base() +
  xlab("Model") +
  ylab("Number of Submissions (Log Scale)")+
  coord_flip()+theme(panel.background = element_blank(),axis.line=element_line(),panel.border = element_blank(),plot.background=element_blank())
dev.off()
  
## Time series figures
site_number <- 1
targetDay <- allTransitions$day15[site_number]
## find the day closest to the target date that had the most forecasts submitted
window = 5
targetRows <- which(lubridate::yday(challengeDays) %in% ((-window:window)+targetDay))
submitted <- apply(gccForecastsYes[targetRows,],1,sum)
startDate <- challengeDays[as.numeric(names(which.max(submitted)))]
  
submissions <- tapply(gcc_forecast_subset$team,INDEX = gcc_forecast_subset$start_time,function(x){length(unique(x))})

submissions <- tapply(gcc_forecast_subset$team,INDEX = gcc_forecast_subset$start_time,function(x){length(x)})

jpeg(file=paste0(figureDirectory,"numberOfSubmissionsOverTime.jpg"),height=4,width=5,units="in",res=1000)
plot(as.Date(names(submissions)),submissions,xlab="Forecast Submission Date",pch=20, ylab= "Total Submissions",main="",bty="n")
dev.off()

```

##Figure 3: Example of forecasted greenness values submitted by teams on 11 May 2021 (4 days before 15%) for Harvard Forest and Supplementary Figure S3: all sites
```{r, echo=FALSE}
## Code from https://github.com/eco4cast/neon4cast/blob/main/notebook/multi_team_plot.R and edited by Kathryn

#' Multi Team Plot of Forecasts 
#'
#' @param combined_forecasts Combined forecast object (eg, gcc_forecast_subset)
#' @param target Target variable (eg, "gcc_90")
#' @param theme Forecast theme (eg, "phenology")
#' @param date Start Date of plots
#' @param horizon Length of forecast (eg, 35)
#' @param siteID Specific site ID (eg, "HARV") and exclude for all 
#' @param team Specific team or exclude for all
#'
#' @return
#' @export
#'
#' @examples
multi_team_plot <- function(combined_forecasts, target, theme, date, horizon, siteID = NA, team = NA){
  curr_theme <- theme
  
  theme_forecasts <- combined_forecasts %>%
    filter(theme == curr_theme)
  
  if(!is.na(siteID)){
    siteID_subset <- siteID
  }else{
    siteID_subset <- unique(theme_forecasts$siteID)
  }
  
  if(!is.na(team)){
    team_subset <- team
  }else{
    team_subset <- unique(theme_forecasts$team)
  }
  
  target_variable <- target
  
  combined_forecasts <- combined_forecasts %>%
    dplyr::filter(target == target_variable,
                  siteID %in% siteID_subset,
                  team %in% team_subset,
                  lubridate::as_date(start_time) %in% lubridate::as_date(date))
  
  combined_forecasts$max_date <- combined_forecasts$start_time + lubridate::days(horizon)
  
  combined_forecasts <- combined_forecasts %>%
    dplyr::mutate(max_date = ifelse(time <= max_date, 1, 0)) %>%
    dplyr::filter(max_date == 1)
  
  if(theme != "terrestrial_30min"){
    combined_forecasts <- combined_forecasts %>%
      mutate(time = lubridate::as_date(time),
             start_time = lubridate::as_date(start_time))
  }
  combined_forecasts$cl <- rep(NA,length(nrow(combined_forecasts)))
  if(!is.na(siteID)){
    specificTeams <- intersect(names(teamCls),unique(combined_forecasts$team))
    specificTeamCls <- teamCls[match(specificTeams,names(teamCls))]
  }else{
    specificTeamCls <- teamCls
  }
  p <- combined_forecasts %>%
    ggplot2::ggplot(aes(x = time, color = team)) +
    ggplot2::geom_line(aes(y = mean)) +
    ggthemes::theme_base()+
    ggplot2::geom_ribbon(aes(x = time, ymin = lower95, ymax = upper95, fill = team), alpha = 0.2) +
    ggplot2::geom_point(aes(y = obs), color = "black", alpha = 0.4) +
    ggplot2::labs(y = "GCC", x = "Time",fill='team') +
    ggplot2::scale_color_manual(values = specificTeamCls) +
    ggplot2::scale_fill_manual(values = specificTeamCls)+
    theme(panel.border = element_blank(), panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"),
plot.background = element_blank(),panel.background = element_blank())
  
  if(is.na(siteID)){
  p <- p + ggplot2::theme(axis.text.x = element_text(angle = 90,
                                              hjust = 0.5, vjust = 0.5))
  }#else{
  # p <- p + ggplot2::theme(axis.text.x = element_text(angle = 45,
  #                                             hjust = 0.5, vjust = 0.5,
  #                                             size = 20),
  #                         axis.text.y=element_text(size=20),
  #                         axis.title=element_text(size=25))
  # p <- p + ggtitle("")
  # }

  if(class(combined_forecasts$time[1])[1] != "Date"){
    #p <- p + ggplot2::scale_x_datetime(date_labels = scales::date_format("%Y-%m-%d"))
  }else{
    p <- p + ggplot2::scale_x_date(labels = scales::date_format("%Y-%m-%d"))
    
  }
  if(length(date) > 1  & length(siteID_subset) > 1){
    
    p + facet_grid(rows = vars(start_time), cols = vars(siteID)) 
    
  }else if(length(date) > 1  & length(siteID_subset) == 1){
    
    p + facet_wrap(vars(start_time)) + labs(title = siteID)
    
  }else if(length(date) == 1  & length(siteID_subset) > 1){
    
    p + facet_wrap(vars(siteID),scales='free_y')
    
  }else{
  p
  }
}

targetDay <- median(allTransitions$day15)
window <- 5
targetRows <- which(lubridate::yday(challengeDays) %in% ((-window:window)+targetDay))
submitted <- apply(gccForecastsYes[targetRows,],1,sum)

submissions <- tapply(gcc_forecast_subset$team,INDEX = gcc_forecast_subset$start_time,function(x){length(unique(x))})
startDate <- as.Date(names(which.max(submissions)))
startDate <- as.Date("2021-04-28")

jpeg(file=paste0(figureDirectory,"exampleForecastsOnDay.jpeg"),width = 8.57, height = 6.01, units = "in",res = 1000)
multi_team_plot(combined_forecasts = gcc_forecast_subset,  
                target = "gcc_90", 
                theme = "phenology", 
                date = startDate, 
                horizon = 35)
dev.off()

startDate <- as.Date("2021-05-11")
jpeg(file=paste0(figureDirectory,"exampleForecastsOnDay_Harvard.jpeg"),width = 10, height = 6, units = "in",res = 1000)
multi_team_plot(combined_forecasts = gcc_forecast_subset, 
                target = "gcc_90", 
                theme = "phenology", 
                date = startDate, 
                horizon = 35,
                siteID = "HARV")
dev.off()

```

#Lead Time Figures: 

##Figure S4 and extras not included: Example of how teams' forecasts change as lead time decreases for two sites for 15%, 50%, and 85% thresholds
```{r, echo=FALSE}
##pdf(file="ForecastedValuesOnTransitionDates_presentationFigures.pdf",height=5,width=12)

#' Plot Forecasted Values of Greenness on Transition Dates with Lead Time
#'
#' @param all_site_number Row number of site(s) in site_names (eg, 1 or c(1,2))
#' @param gcc_forecast_subset Forecasts object
#' @param statistic The desired statistic or gcc to plot("GCC","CRPS", "bias" or "sd")
#' @param ylims Vector of the limits for the y-axis (e.g., (0,1))
#' @param rescaled Logical for if you want to rescale forecasted values between 0 and 1 instead of raw gcc_90 values
#'
#' @return
#' @export
#'
#' @examples
plotForecastedValuesOverTime <- function(all_site_number, gcc_forecast_subset,statistic,ylims, rescaled, trans=c(2,5,8)){
  if(length(all_site_number)==1){
    par(mfrow=c(length(all_site_number),(length(trans)+1)),mai=c(0.4,0.5,0.2,0.1))
  }else if(length(all_site_number)==2){
    if(length(trans)==3){
      layout(matrix(c(1,4,2,5,3,6,7,7),ncol=(length(trans)+1),byrow=FALSE))
    }else if(length(trans)==2){
      layout(matrix(c(1,3,2,4,5,5),ncol=(length(trans)+1),byrow=FALSE))
    }else{
      print("Not compatible with number of transition dates")
      return()
    }
    par(mai=c(0.4,0.5,0.2,0.1))
  }else{
    print("Unknown number of sites")
    return()
  }
  
  if(length(all_site_number)>1){
    multipleSites=TRUE
  }else{
    multipleSites=FALSE
  }
  finalTms <- character()
  plottedCls <- character()
  
  for(site_number in all_site_number){
    sitDat <- gcc_forecast_subset[gcc_forecast_subset$siteID==site_names[site_number],]
    for(t in trans){ #Loops over the transition dates
      tranDate <- as.Date(unlist(allTransitions[site_number,t]),origin=as.Date("2020-12-31"))
      cl <- 1
      vl <- as.numeric(allTransitions[site_number,(t+1)])
      sdVal <- allTransitions[site_number,(t+2)]
      if(!multipleSites){ #If there is only 1 site it will automatically add the panel letterings and titles
        if(t==2){
          tle <- paste("a)",site_names[site_number],"15%")
        }else if(t == 5){
          tle <- paste("b)",site_names[site_number],"50%")
        }else if(t==8){
          tle <- paste("c)",site_names[site_number],"85%")
        }
      }else{
        tle <- "" #Titles added outside of R
      }
      if(rescaled){
        vl <- rescale(vl,to=c(0,1),from=c(allTransitions$minimum[site_number],allTransitions$maximum[site_number])) ##Rescales gcc values between 0 and 1
      }
      if(multipleSites){
        plot(x=numeric(),y=numeric(),type="l",xlim=c(-35,0),ylim=ylims,ylab="",xlab="",main="",bty="n",axes = FALSE)
        if(site_number==all_site_number[1]){
          axis(1, at=seq(-35,0,5),labels=rep("",8))
        }else if(site_number==all_site_number[2]){
          axis(1, at=seq(-35,0,5),labels=seq(-35,0,5))
        }
        if(t==2){
          axis(2, at=seq(ylims[1],ylims[2],length.out = 5),labels=seq(ylims[1],ylims[2],length.out = 5))
        }else{
          axis(2, at=seq(ylims[1],ylims[2],length.out = 5),labels=rep("",5))
        }
      }else{
        plot(x=numeric(),y=numeric(),type="l",xlim=c(-35,0),ylim=ylims,ylab="",xlab="Lead Time",main=tle,bty="n")
      }
      if(statistic=="GCC"){
        abline(h=vl,col="black",lwd=5,lty=2)
      }
      for(tm in 1:n_teams){
        tmSitDat <- sitDat[sitDat$team==teams[tm],] #Subset by team
        allPlottedData <- matrix(nrow=length(site_names),ncol=35) #35 columns for the different forecast horizons 
        tranDate <- as.Date(unlist(allTransitions[site_number,t]),origin=as.Date("2020-12-31"))
        beforeDays <- seq(tranDate-34,tranDate,by="day")
        organizedDat <- tmSitDat[as.Date(tmSitDat$time)==tranDate,] #Subset of the forecasts that forecasted the transition date 
        if(nrow(organizedDat)>0){
          if(t==8){
            if(! as.character(teams[tm]) %in% finalTms){
              finalTms <- c(finalTms,as.character(teams[tm]))
              plottedCls <- c(plottedCls,cls[tm])
            }
          }
          sitTmMax <- max(organizedDat$mean,na.rm=TRUE)
          if(statistic=="GCC"){
            if(rescaled){
              rescaledDat <- rescale(organizedDat$mean,to=c(0,1),from=c(allTransitions$minimum[site_number],allTransitions$maximum[site_number]))#sitTmMax)) #Rescales forecasted values between 0 and 1
            }else{
              rescaledDat <- organizedDat$mean
            }
            for(j in 1:length(rescaledDat)){ #Some values get scaled below 0 
              rescaledDat[j] <- max(rescaledDat[j],0)
            }
            for(d in 1:length(beforeDays)){ #Not all teams submitted forecasts for all 35 forecast horizons 
              replacement <- rescaledDat[organizedDat$start_time==beforeDays[d]]
              if(length(replacement)==0){
                if(d>1){
                  if(!is.na(allPlottedData[site_number,(d-1)])){
                    replacement <- allPlottedData[site_number,(d-1)] #filling in missing predictions with the previous day's 
                  }else{
                    replacement <- NA   
                  }
                }else{
                  replacement <- NA   
                }
              }
              allPlottedData[site_number,d] <- replacement[length(replacement)]#Some teams occassionally submitted multiple forecasts on a day so taking the last one submitted
            }
            computedStat <- colMeans(allPlottedData,na.rm = TRUE)
            leadTimes <- seq(35,1)
          }else{
            leadTimes <- tranDate-as.Date(organizedDat$start_time)
            if(statistic=="bias"){
              computedStat <- vl-organizedDat$mean
            }else if(statistic=="CRPS"){
              computedStat <- organizedDat$crps
            }else if(statistic=="sd"){
              computedStat <- organizedDat$sd
            }
          }
          lines(-1*leadTimes,computedStat,col=cls[tm],lwd=2)
        }
      }
    }
    if(site_number==all_site_number[length(all_site_number)]){
      plot(x=numeric(),y=numeric(),type="l",xlim=c(-35,0),ylim=c(0,1),ylab="",xlab="",main="",bty="n",xaxt="n",yaxt="n")
      legend("topleft",c("Observed",as.character(finalTms)),col=c("black",plottedCls),lty=c(2,rep(1,length(finalTms))),lwd=c(4,rep(3,length(finalTms))),bty = "n")
    }
  }
}

jpeg(file=paste0(figureDirectory,"forecastedValuesOfTransitionDates.jpeg"),width = 9, height = 5, units = "in",res = 1000) ##Figure S4
plotForecastedValuesOverTime(all_site_number=c(8,2),gcc_forecast_subset=gcc_forecast_subset,statistic = "GCC", ylims=c(0.32,0.46),rescaled=FALSE,trans=c(2,8))
dev.off()

##Extra Figures
jpeg(file=paste0(figureDirectory,"forecastedValuesOfTransitionDates_rescaled.jpeg"),width = 9, height = 5, units = "in",res = 1000) #Not included for simplicity
plotForecastedValuesOverTime(all_site_number=c(8,2),gcc_forecast_subset=gcc_forecast_subset,statistic = "GCC", ylims = c(0,1), rescaled=TRUE,trans=c(2,8))
dev.off()


jpeg(file=paste0(figureDirectory,"BiasvsLeadTimeTrans.jpeg"),width = 9, height = 5, units = "in",res = 1000) #Not included for simplicity
plotForecastedValuesOverTime(all_site_number=c(6,2),gcc_forecast_subset=gcc_forecast_subset,statistic = "bias", ylims=c(-0.05,0.12),rescaled=FALSE)
dev.off()

jpeg(file=paste0(figureDirectory,"SDvsLeadTimeTrans.jpeg"),width = 9, height = 5, units = "in",res = 1000) #Not included for simplicity
plotForecastedValuesOverTime(all_site_number=c(6,2),gcc_forecast_subset=gcc_forecast_subset,statistic = "sd", ylims=c(0,0.05),rescaled=FALSE)
dev.off()

```

#Figure S5 CRPS examples over lead time
```{r}
jpeg(file=paste0(figureDirectory,"CRPSvsLeadTimeTrans.jpeg"),width = 9, height = 5, units = "in",res = 1000)
ylims <- rbind(rbind(rbind(c(0,0.02),c(0,0.04)),c(0,0.03)),c(0,0.1))
all_site_number=c(8,2)
statistic = "CRPS"
trans=c(2,8)

layout(matrix(c(1,3,2,4,5,5),ncol=(length(trans)+1),byrow=FALSE))
par(mai=c(0.4,0.5,0.2,0.1))

finalTms <- character()
plottedCls <- character()
ct <- 1
for(site_number in all_site_number){
  sitDat <- gcc_forecast_subset[gcc_forecast_subset$siteID==site_names[site_number],]
  for(t in trans){ #Loops over the transition dates
    tranDate <- as.Date(unlist(allTransitions[site_number,t]),origin=as.Date("2020-12-31"))
    cl <- 1
    vl <- as.numeric(allTransitions[site_number,(t+1)])
    sdVal <- allTransitions[site_number,(t+2)]
    
    plot(x=numeric(),y=numeric(),type="l",xlim=c(-35,0),ylim=ylims[ct,],ylab="",xlab="",main="",bty="n",xaxt="n")
    ct <- ct+1
    if(site_number==all_site_number[1]){
      axis(1, at=seq(-35,0,5),labels=rep("",8))
    }else if(site_number==all_site_number[2]){
      axis(1, at=seq(-35,0,5),labels=seq(-35,0,5))
    }
    
    for(tm in 1:n_teams){
      tmSitDat <- sitDat[sitDat$team==teams[tm],] #Subset by team
      allPlottedData <- matrix(nrow=length(site_names),ncol=35) #35 columns for the different forecast horizons 
      tranDate <- as.Date(unlist(allTransitions[site_number,t]),origin=as.Date("2020-12-31"))
      beforeDays <- seq(tranDate-34,tranDate,by="day")
      organizedDat <- tmSitDat[as.Date(tmSitDat$time)==tranDate,] #Subset of the forecasts that forecasted the transition date 
      if(nrow(organizedDat)>0){
        if(t==8){
          if(! as.character(teams[tm]) %in% finalTms){
            finalTms <- c(finalTms,as.character(teams[tm]))
            plottedCls <- c(plottedCls,cls[tm])
          }
        }
        sitTmMax <- max(organizedDat$mean,na.rm=TRUE)
        
        leadTimes <- tranDate-as.Date(organizedDat$start_time)
        computedStat <- organizedDat$crps
        lines(-1*leadTimes,computedStat,col=cls[tm],lwd=2)
      }
    }
  }
}
plot(x=numeric(),y=numeric(),type="l",xlim=c(-35,0),ylim=c(0,1),ylab="",xlab="",main="",bty="n",xaxt="n",yaxt="n")
legend("topleft",as.character(finalTms),col=plottedCls,lty=1,lwd=3,bty = "n")

dev.off()
```

##Figure S6. Calculate the lead times that each model and site performed better than climatology (lower CRPS) for different transition dates
```{r}
allForecastHorizons_clim <- matrix(nrow=0,ncol=4)

for(s in 1:length(site_names)){
  sitDat <- gcc_forecast_subset[gcc_forecast_subset$siteID==site_names[s],] 
  sitDat_DOY_Mean <- sitDat[sitDat$team=="DOY_Mean",]
  
  for(t in c(2,5,8)){ #Loops over the transition dates
    tranDate <- as.Date(unlist(allTransitions[s,t]),origin=as.Date("2020-12-31"))
    vl <- as.numeric(allTransitions[s,(t+1)])
    vl <- round(rescale(vl,to=c(0,1),from=c(allTransitions$minimum[s],allTransitions$maximum[s])),digits=2)
    clim_tranDat <- sitDat_DOY_Mean[as.Date(sitDat_DOY_Mean$time)==tranDate,]
    clim_tranDat <- clim_tranDat[3:37,]
    for(tm in 1:n_teams){
      tmSitDat <- sitDat[sitDat$team==teams[tm],] #Subset by team
      tm_tranDat <- tmSitDat[as.Date(tmSitDat$time)==tranDate,]
      if(nrow(tm_tranDat)>0){
        mergedDat <- merge(tm_tranDat,clim_tranDat,'start_time')
        forecastHorizon <- as.numeric(tranDate-mergedDat$start_time[which(mergedDat$crps.x<=mergedDat$crps.y)[1]])
        if(length(forecastHorizon)==0 | is.na(forecastHorizon)){
          forecastHorizon <- 0
        }
        allForecastHorizons_clim <- rbind(allForecastHorizons_clim,
                                          c(site_names[s],vl,teams[tm],forecastHorizon))
      }else{ #Team didn't forecast this date
        allForecastHorizons_clim <- rbind(allForecastHorizons_clim,
                                          c(site_names[s],vl,teams[tm],NA))
      }
    }
  }
}
allForecastHorizons_clim <- data.frame(site=allForecastHorizons_clim[,1],
                                       trans=allForecastHorizons_clim[,2],
                                       tm=allForecastHorizons_clim[,3],                                      forecastHorizon=allForecastHorizons_clim[,4],
                                       tmAvg=rep(NA,nrow(allForecastHorizons_clim)),
                                       tmMin=rep(NA,nrow(allForecastHorizons_clim)),
                                       tmMax=rep(NA,nrow(allForecastHorizons_clim)))

for(i in 1:nrow(allForecastHorizons_clim)){
  tmSubset <- allForecastHorizons_clim[allForecastHorizons_clim[,3]==allForecastHorizons_clim[i,3],]
  tmSubsetTran <- tmSubset[tmSubset[,2]==allForecastHorizons_clim[i,2],]
  allForecastHorizons_clim[i,5] <- mean(as.numeric(tmSubsetTran[,4]),na.rm=TRUE)
  allForecastHorizons_clim$tmAvg[i] <- mean(as.numeric(tmSubsetTran[,4]),na.rm=TRUE)
  allForecastHorizons_clim$tmMin[i] <- min(as.numeric(tmSubsetTran[,4]),na.rm=TRUE)
  allForecastHorizons_clim$tmMax[i] <- max(as.numeric(tmSubsetTran[,4]),na.rm=TRUE)
  if(is.nan(allForecastHorizons_clim[i,5])){
    allForecastHorizons_clim[i,5] <- 0
  }
}
d <- as.data.frame(allForecastHorizons_clim)
d <- d %>% 
  subset(tm != "DOY_Mean") %>%
  ungroup() %>%
  arrange(as.factor(trans),-as.numeric(as.character(tmAvg)),as.factor(tm))

d$tmMin[(d$tmMin=="Inf")] <- NA
d$tmMin[(d$tmMin=="-Inf")] <- NA
d$tmMax[(d$tmMax=="Inf")] <- NA
d$tmMax[(d$tmMax=="-Inf")] <- NA

d$tmAvg[as.character(d$tm)=="PEG_RFR2" & d$trans==0.15] <- 0.99 #Hack to get ordering correct

jpeg(file=paste0(figureDirectory,"ForecastHorizonsAtTransitionDates.jpg"),width = 9, height = 4.5, units = "in",res=1000)
d2 <- d[d$trans==0.15,]
p1 <- ggplot(d2,aes(as.numeric(as.character(forecastHorizon)),fct_reorder(tm,tmAvg))) +
  geom_density_ridges2(scale=1)+
  xlab("Forecast Horizon (Days)")+
  ylab("Density of Sites per Model")+
  scale_x_continuous(limits=c(0,35))+
  ggtitle("a) 15%")+
  ggthemes::theme_base()+
  theme(axis.text.x = element_text(angle=90),panel.background = element_blank(),axis.line=element_line(),panel.border = element_blank(),
                                                             plot.background=element_blank(),
        plot.title = element_text(face="plain"))

d2 <- d[d$trans==0.85,]
p2 <- ggplot(d2,aes(as.numeric(as.character(forecastHorizon)),fct_reorder(tm,tmAvg))) +
  geom_density_ridges2(scale=1)+
  ggthemes::theme_base()+
  theme(axis.text.x = element_text(angle=90),panel.background = element_blank(),axis.line=element_line(),panel.border = element_blank(),
                                                             plot.background=element_blank(),
        plot.title = element_text(face="plain"))+
  xlab("Forecast Horizon (Days)")+
  ylab("")+
  scale_x_continuous(limits=c(0,35))+
  ggtitle("b) 85%")
grid.arrange(p1,p2,nrow=1)

dev.off()

```

#Supplementary Figure S8 (DOY of transition date anomalies) and other tables/figures not included 
```{r}
allMeans <- matrix(nrow=0,ncol=4)
allAnomalies <- matrix(nrow=0,ncol=4)
allTransitionDys <- allTransitions[,c('siteID','day15','day50','day85')]
meanTrans <- read.csv(file="historicalMeanTransitionDates.csv") #Created in calculatePhenoCamTransitionDates.R file
for(s in 1:n_sites){
  selectedSite <- site_names[s]
  siteALL <- gcc_forecast_subset[gcc_forecast_subset$siteID==selectedSite,]
  
  site1 <- siteALL[lubridate::date(siteALL$time)==(as.Date("2020-12-31")+as.numeric(allTransitionDys[allTransitionDys$siteID==selectedSite,2])),]
  site2 <- siteALL[lubridate::date(siteALL$time)==(as.Date("2020-12-31")+as.numeric(allTransitionDys[allTransitionDys$siteID==selectedSite,3])),]
  site3 <- siteALL[lubridate::date(siteALL$time)==(as.Date("2020-12-31")+as.numeric(allTransitionDys[allTransitionDys$siteID==selectedSite,4])),]
  
  allMeans <- rbind(allMeans,c(selectedSite,'15%',round((mean(site1$crps,na.rm=TRUE)),digits=3),round((sd(site1$crps,na.rm=TRUE)),digits=3)))
    allMeans <- rbind(allMeans,c(selectedSite,'50%',round((mean(site2$crps,na.rm=TRUE)),digits=3),round((sd(site2$crps,na.rm=TRUE)),digits=3)))
    allMeans <- rbind(allMeans,c(selectedSite,'85%',round((mean(site3$crps,na.rm=TRUE)),digits=3),round((sd(site3$crps,na.rm=TRUE)),digits=3)))
  
  #Add columns for the historical average day of year transition
  allAnomalies <- rbind(allAnomalies,
                        c(selectedSite,'15%',round((as.numeric(allTransitionDys[allTransitionDys$siteID==selectedSite,2])-
                                 meanTrans[meanTrans$siteID==selectedSite,'day15']),digits=3),
                          round(meanTrans[meanTrans$siteID==selectedSite,'sd15'],digits=3)))
  
    allAnomalies <- rbind(allAnomalies,
                        c(selectedSite,'50%',round((as.numeric(allTransitionDys[allTransitionDys$siteID==selectedSite,3])-
                                 meanTrans[meanTrans$siteID==selectedSite,'day50']),digits=3),
                          round(meanTrans[meanTrans$siteID==selectedSite,'sd50'],digits=3)))
    
      allAnomalies <- rbind(allAnomalies,
                        c(selectedSite,'85%',round((as.numeric(allTransitionDys[allTransitionDys$siteID==selectedSite,4])-
                                 meanTrans[meanTrans$siteID==selectedSite,'day85']),digits=3),
                          round(meanTrans[meanTrans$siteID==selectedSite,'sd85'],digits=3)))
}

allMeans <- data.frame(allMeans)
colnames(allMeans) <- c("Site","Transition","CRPS","CRPS_SD")
allMeans$CRPS <- as.numeric(as.character(allMeans$CRPS))
allMeans$CRPS_SD <- as.numeric(as.character(allMeans$CRPS_SD))
allMeans$siteFullName <- site_full_names[match(allMeans$Site,names(site_full_names))]

allAnomalies <- data.frame(allAnomalies)
colnames(allAnomalies) <- c("Site","Transition","Anomaly","Anomaly_SD")
allAnomalies$Anomaly <- as.numeric(as.character(allAnomalies$Anomaly))
allAnomalies$Anomaly_SD <- as.numeric(as.character(allAnomalies$Anomaly_SD))
allAnomalies$siteFullName <- site_full_names[match(allAnomalies$Site,names(site_full_names))]


jpeg(file=paste0(figureDirectory,"averageCRPSvalues_transitionDates.jpeg"),width = 9, height = 5, units = "in",res=1000) #Not included

ggplot(allMeans,aes(fill=Transition,y=CRPS,x=siteFullName))+
  geom_bar(position=position_dodge(),stat="identity")+  
  geom_errorbar(aes(ymin=CRPS-CRPS_SD,ymax=CRPS+CRPS_SD), width=0.4, colour="black", size=0.5,position=position_dodge(0.9))+
  xlab("Site")+
  ggthemes::theme_base()+theme(panel.background = element_blank(),axis.line=element_line(),panel.border = element_blank(),
                                                             plot.background=element_blank())
  
dev.off()

##Supplementary Figure
jpeg(file=paste0(figureDirectory,"transitionDate_anomalies.jpeg"),width = 8, height = 5, units = "in",res=1000)

ggplot(allAnomalies,aes(fill=Transition,y=Anomaly,x=siteFullName))+
  geom_bar(position=position_dodge(),stat="identity")+  
  geom_errorbar(aes(ymin=Anomaly- 1.000001 *Anomaly_SD,ymax=Anomaly+1.000001*Anomaly_SD), width=0.4, colour="black", size=0.5,position=position_dodge(0.9))+
  ylab("Days After Historical Average")+
  xlab("Site")+
  ggthemes::theme_base()+theme(panel.background = element_blank(),axis.line=element_line(),panel.border = element_blank(),
                                                             plot.background=element_blank(),
                               axis.text.x = element_text(angle = 90,
                                              hjust = 0.5, vjust = 0.5))
dev.off()
```


## Metadata processing for GAMs (Needs to be Run)
```{r}
if(!file.exists('gcc_forecast_subset_20220415.RData')){
  ## grab the names of all the EMLs
  meta_reload = FALSE
  if(meta_reload){
    ## New version
    obj <- arrow::s3_bucket("forecasts/phenology", endpoint_override="data.ecoforecast.org")
    obj$ls()  
    
    ## OLD: grab the names of all the EMLs
    obj <- aws.s3::get_bucket("forecasts",
                              prefix = "phenology",
                              region = "data",
                              base_url = "ecoforecast.org",
                              max = Inf)
    object = as.data.frame(obj)
    emls = which(tools::file_ext(object$Key) == "xml")
    ## find the most recent for each team
    eparse <- gsub(pattern = "phenology-",replacement = "",x = basename(object$Key),fixed = TRUE)
    edate <- as.Date(substr(eparse,1,10))
    eteam <- substring(eparse,12)
    object = cbind(object,edate,eteam)
    ## only 4 teams sent in EML!!!!
    toGrab = object[emls,] %>% group_by(eteam) %>% slice_max(edate)
    fname = rep(NA,nrow(toGrab))
    for(i in seq_along(fname)){
      fname[i] = aws.s3::save_object(obj[[which(object[,"Key"]==toGrab$Key[i])]], 
                                     bucket = "forecasts", 
                                     region = "data",
                                     base_url = "ecoforecast.org")
    }
    
    nsobj<- aws.s3::get_bucket("forecasts",
                               prefix = "not_in_standard",
                               region = "data",
                               base_url = "ecoforecast.org",
                               max = Inf)
    nsobject = as.data.frame(nsobj)
    nsemls = which(tools::file_ext(nsobject$Key) %in% c("xml","eml","yml"))
    nsemls = nsemls[grepl("phenology",nsobject[nsemls,"Key"])]
    # nsobject[nsemls,"Key"]
    ## one additional team had XML that failed to parse, and a couple more had .eml and .yml files
    toGrab = c("not_in_standard/phenology-metadata-VT_Ph_GDD.yml","not_in_standard/phenology-2021-05-09-CU_Pheno.yml","not_in_standard/phenology-2021-04-14-UCSC_P_EDM.eml","not_in_standard/phenology-2021-03-19-PEG.xml")
    fname2 = rep(NA,length(toGrab))
    for(i in seq_along(toGrab)){
      fname2[i] = aws.s3::save_object(nsobj[[which(nsobject[,"Key"]==toGrab[i])]], 
                                      bucket = "forecasts", 
                                      region = "data",
                                      base_url = "ecoforecast.org")
    }
    fname = c(fname,fname2)
    fname
  } else {
    ## LOAD XML FILES LOCALLY
    fname = dir(pattern = "[exy]ml")
  }
  
  lexists <- function(list,name){
    if(name %in% names(list)){
      if(is.null(list[[name]])){
        return(FALSE)
      } else {
        return(TRUE)
      }
    } else {
      return(FALSE)
    }
  }
}
```

#(Needs to Be Run)
```{r}
if(!file.exists('gcc_forecast_subset_20220415.RData')){
  ## Things we want to pull out::
  ## model type
  ## for each uncertainty: status, complexity
  meta <- as.data.frame(matrix(NA,n_teams,13))
  row.names(meta) <- teams
  colnames(meta) <- c("type","name","drivers","ndrivers","initial_conditions","ninitial_conditions","parameters","nparameters","process_error","nprocess_error","obs_error","random_effects","nrandom_effects")
  for(i in seq_along(fname)){
    j = names(unlist(tapply(teams,teams,grep,fname[i])))
    if(tools::file_ext(fname[i]) %in% c("xml","eml")){
      md <- EML::read_eml(fname[i])
      md <- EML::eml_get(md, "additionalMetadata") %>% EML::eml_get("forecast")
    } else {
      md = yaml::read_yaml(fname[i])
      md = md$metadata$forecast  
    }
    if(lexists(md,"model_description")){
      meta[j,"type"] = md$model_description$type
      if(lexists(md$model_description,"name"))    meta[j,"name"] = md$model_description$name
    }
    if(lexists(md,"drivers")){
      if(lexists(md$drivers,"status")) meta[j,"drivers"] = md$drivers$status
      if(lexists(md$drivers,"complexity")) meta[j,"ndrivers"] = md$drivers$complexity
    }
    if(lexists(md,"initial_conditions")){
      if(lexists(md$initial_conditions,"status")) meta[j,"initial_conditions"] = md$initial_conditions$status
      if(lexists(md$initial_conditions,"complexity")) meta[j,"ninitial_conditions"] = md$initial_conditions$complexity
    }
    if(lexists(md,"parameters")){
      if(lexists(md$parameters,"status"))meta[j,"parameters"] = md$parameters$status
      if(lexists(md$parameters,"complexity")) meta[j,"nparameters"] = md$parameters$complexity
    }
    if(lexists(md,"process_error")){
      if(lexists(md$process_error,"status")) meta[j,"process_error"] = md$process_error$status
      if(lexists(md$process_error,"complexity")) meta[j,"nprocess_error"] = md$process_error$complexity
    }
    if(lexists(md,"obs_error")){
      if(lexists(md$obs_error,"status")) meta[j,"obs_error"] = md$obs_error$status
    }
    if(lexists(md,"random_effects")){
      if(lexists(md$random_effects,"status")) meta[j,"random_effects"] = md$random_effects$status
      if(lexists(md$random_effects,"complexity")) meta[j,"nrandom_effects"] = md$random_effects$complexity
    }
  }
  
  ## Recoding
  meta$drivers[meta$drivers == "absent"] = FALSE
  meta$drivers[!is.na(meta$drivers) & meta$drivers != FALSE] = TRUE
  meta$initial_conditions[meta$initial_conditions == "absent"] = FALSE
  meta$initial_conditions[!is.na(meta$initial_conditions) & meta$initial_conditions != FALSE] = TRUE
  
  ## hacks
  meta[c("PEG","PEG_RFR2","greenbears_gams","greenbears_stl","VT_Ph_GDD","EFI_U_P","Fourier","Team_MODIS"),"initial_conditions"] = FALSE
  meta[c("PEG_RFR","PEG_RFR0","DALEC_SIP","PhenoPhriends","EFInull","CU_Pheno"),"initial_conditions"] = TRUE
  
  meta[c("PEG","greenbears_gams","greenbears_stl","EFInull","Fourier"),"drivers"] = FALSE
  meta[c("PEG_RFR","PEG_RFR0","PEG_RFR2","DALEC_SIP","PhenoPhriends","greenbears_par","VT_Ph_GDD","EFI_U_P","Team_MODIS","CU_Pheno"),"drivers"] = TRUE
  
  meta["VT_Ph_GDD","type"] = "statistical"
  
  meta$class <- paste0(meta$drivers,meta$initial_conditions)
  meta$team <- rownames(meta)
  meta$class[meta$team == "climatology"] = "clim"
}

meta <- meta %>% mutate(team=replace(team,team=="climatology","DOY_Mean")) %>% mutate(team=replace(team,team=="EFInull","Persistence")) %>%
  mutate(team=replace(team,team=="UCSC_P_EDM","GPEDM"))
row.names(meta) <- meta$team
meta["PEG","class"] <- "TRUETRUE"

```

## Lead Time Stats

Prep data (Need to Run)
```{r, echo=FALSE}
gcc_forecast_subset3 <- gcc_forecast_subset %>% left_join(y=meta,by = "team")

table(gcc_forecast_subset3$class)

matchSite <- match(gcc_forecast_subset$siteID, allTransitions$siteID)
gcc_forecast_subset2 <- gcc_forecast_subset3 %>%
  mutate(day85 = allTransitions$day85[matchSite],
         day50 = allTransitions$day50[matchSite],
         day15 = allTransitions$day15[matchSite],
         phenoDate = lubridate::yday(start_time) - day15,
         phenoDate_time = lubridate::yday(time) - day15)

#phenoDate is the number of days after the 15% green-up date of the submission date
#phenoDate_time is number of days after 15% green-up of the forecasted date
```

Linear models
```{r, echo=FALSE}
fit <- lm(crps ~ siteID + horizon + team + phenoDate,data = gcc_forecast_subset2)
summary(fit)

fit3 <- lm(crps ~ siteID + horizon + phenoDate + class,data = gcc_forecast_subset2)
summary(fit3)
```


Overall GAM: site, team, horizon, phenoDate
```{r, echo=FALSE}
## overall model
gcc_forecast_subset2 <- gcc_forecast_subset2 %>% mutate(team=replace(team,team=="DOY_Mean"," DOY_Mean")) #Need DOY_Mean to be the first alphabetical team name for fixed effects in GAM
meta <- meta %>% mutate(team=replace(team,team=="DOY_Mean"," DOY_Mean")) #Need DOY_Mean to be the first alphabetical team name for fixed effects in GAM

fit2 <- mgcv::gam(crps ~ siteID + s(horizon) + team + s(phenoDate),
            data = gcc_forecast_subset2,
            method="REML") #PhenoDate being the date of submission

summary(fit2)

fit2_time <- mgcv::gam(crps ~ siteID + s(horizon) + team + s(phenoDate_time),
            data = gcc_forecast_subset2,
            method="REML") #PhenoDate being the forecasted date

## model with interactions
fit2i <- mgcv::gam(crps ~ siteID  + team + siteID*team + s(horizon)+ s(phenoDate),
            data = gcc_forecast_subset2,
            method="REML")
summary(fit2i)

## fit by class instead of team
fit4a <- mgcv::gam(crps ~ siteID + class + s(horizon) + s(phenoDate),
           data = gcc_forecast_subset2,
           method="REML")
summary(fit4a)
classEffect = data.frame(class=c("static","covariate","dynamic"),
                         mu=coef(fit4a)[c("classFALSEFALSE","classTRUEFALSE","classTRUETRUE")])


## team effect
beta = summary(fit2)$p.table
beta.team = as.data.frame(beta[grepl("team",row.names(beta)),]) %>% 
  mutate(team = sub("team","",rownames(.))) %>% left_join(y=meta,by="team") %>% arrange(Estimate)
colnames(beta.team)[2] <- "SE"
beta.team$team = reorder(beta.team$team,beta.team$Estimate)
beta.team$class = recode(beta.team$class, TRUETRUE = "dynamic", FALSEFALSE = "static",FALSETRUE="persist",TRUEFALSE="covariate")

```


#Figure 7: GAM fixed effects by model relative to DOY_mean (clim) model
```{r}
jpeg(file=paste0(figureDirectory,"GAM_TeamsComparedToClim.jpeg"),width = 8.5, height = 5, units = "in",res=1000)
ggplot(beta.team) + 
  geom_bar( aes(x=team, y=Estimate, fill=class),
            stat="identity",
            alpha=0.75) +
  xlab("Model")+
  ggthemes::theme_base()+
 geom_errorbar( aes(x=team, ymin=Estimate-1.96*SE, ymax=Estimate+1.96*SE), width=0.4, colour="black", alpha=0.9, size=0.8) +
  coord_flip() + ylab("CRPS(Model) - CRPS(DOY Mean)") +theme(legend.position = c(0.85, 0.2), panel.background = element_blank(),axis.line=element_line(),panel.border = element_blank(),
                                                             plot.background=element_blank()) +
  scale_fill_brewer(palette="Dark2")+
  geom_hline(yintercept = classEffect$mu[1],size=1,
             colour=RColorBrewer::brewer.pal(4,"Dark2")[4]) +
  geom_hline(yintercept = classEffect$mu[2],size=1
             ,colour=RColorBrewer::brewer.pal(4,"Dark2")[1]) +
  geom_hline(yintercept = classEffect$mu[3],size=1
             ,colour=RColorBrewer::brewer.pal(4,"Dark2")[2])

dev.off()

#Check uncertainties in DOY_mean and greenbear_par
gcc_forecast_subset_greenbearspar <- gcc_forecast_subset2[gcc_forecast_subset$team=="greenbears_par",]
gcc_forecast_subset_DOYmean <- gcc_forecast_subset2[gcc_forecast_subset$team=="DOY_Mean",]

mean(gcc_forecast_subset_DOYmean$sd,na.rm=TRUE)
mean(gcc_forecast_subset_greenbearspar$sd,na.rm=TRUE) #Much lower standard deviation 
t.test(gcc_forecast_subset_DOYmean$sd,gcc_forecast_subset_greenbearspar$sd)
```

#Figure 8 ans S9: Site Effects in GAMs
```{r}
## site effect
beta.site = as.data.frame(rbind(beta[1,],beta[grepl("site",row.names(beta)),])) %>% mutate(site=rownames(.)) 
beta.site$site = gsub("siteID","",beta.site$site)
beta.site$site[1]="BART"
colnames(beta.site)[2] <- "SE"
bcov = vcov(fit2)[1:8,1:8]
beta.site$Estimate[2:8] = beta.site$Estimate[2:8] + beta.site$Estimate[1] ## rescale mean
beta.site$SE[2:8] = sqrt(beta.site$SE[2:8]^2 + beta.site$SE[1]^2 + 2*bcov[2:8,1]) ## rescale SE
beta.site = beta.site %>% left_join(y=allTransitions,by=c("site"="siteID")) %>% arrange(day50)
beta.site$anomaly15 <- NA
beta.site$anomaly50 <- NA
beta.site$anomaly85 <- NA

for(s in 1:nrow(beta.site)){
  beta.site$anomaly15[s] <- allAnomalies[(allAnomalies$Site==as.character(beta.site$site[s])&
                               allAnomalies$Transition=="15%"),'Anomaly']
  beta.site$anomaly50[s] <- allAnomalies[(allAnomalies$Site==as.character(beta.site$site[s])&
                               allAnomalies$Transition=="50%"),'Anomaly']
  beta.site$anomaly85[s] <- allAnomalies[(allAnomalies$Site==as.character(beta.site$site[s])&
                               allAnomalies$Transition=="85%"),'Anomaly']
}

jpeg(file=paste0(figureDirectory,"sitePredictability_LinearRegressions.jpeg"),width = 7, height = 4.5, units = "in",res=1000)
par(mai=c(0.6,0.6,0.4,0.1))
par(mfrow=c(2,3))

siteLM = lm(Estimate ~ day15,beta.site)
plot(beta.site$day15,beta.site$Estimate,xlab="DOY of 15% Greenup",ylab="Site Predictability",pch=20,bty="n")
title("a)", adj = 0)
abline(siteLM)
sm <- summary(siteLM)
text(80,0.0078,paste('p-value:',round(sm$coefficients[2,4],digits=3)),pos=4)
text(80,0.007,parse(text=paste0("R^2",":",round(sm$r.squared,digits=3))),pos=4)

siteLM = lm(Estimate ~ day50,beta.site)
plot(beta.site$day50,beta.site$Estimate,xlab="DOY of 50% Greenup",ylab="",pch=20,bty="n")
abline(siteLM)
title("b)", adj = 0)
sm <- summary(siteLM)
text(87,0.0078,paste('p-value:',round(sm$coefficients[2,4],digits=3)),pos=4)
text(87,0.007,parse(text=paste0("R^2",":",round(sm$r.squared,digits=3))),pos=4)

siteLM = lm(Estimate ~ day85,beta.site)
plot(beta.site$day85,beta.site$Estimate,xlab="DOY of 85% Greenup",ylab="",pch=20,bty="n")
abline(siteLM)
title("c)", adj = 0)
sm <- summary(siteLM)
text(93,0.0078,paste('p-value:',round(sm$coefficients[2,4],digits=3)),pos=4)
text(93,0.007,parse(text=paste0("R^2",":",round(sm$r.squared,digits=3))),pos=4)

siteLM = lm(Estimate ~ anomaly15,beta.site)
plot(beta.site$anomaly15,beta.site$Estimate,xlab="DOY Anomaly of 15% Greenup",ylab="Site Predictability",pch=20,bty="n")
title("d)", adj = 0)
abline(siteLM)
sm <- summary(siteLM)
text(-6,0.004,paste('p-value:',round(sm$coefficients[2,4],digits=3)),pos=4)
text(-6,0.0032,parse(text=paste0("R^2",":",round(sm$r.squared,digits=3))),pos=4)

siteLM = lm(Estimate ~ anomaly50,beta.site)
plot(beta.site$anomaly50,beta.site$Estimate,xlab="DOY Anomaly of 50% Greenup",ylab="",pch=20,bty="n")
abline(siteLM)
title("e)", adj = 0)
sm <- summary(siteLM)
text(-6,0.004,paste('p-value:',round(sm$coefficients[2,4],digits=3)),pos=4)
text(-6,0.0032,parse(text=paste0("R^2",":",round(sm$r.squared,digits=3))),pos=4)

siteLM = lm(Estimate ~ anomaly85,beta.site)
plot(beta.site$anomaly85,beta.site$Estimate,xlab="DOY Anomaly of 85% Greenup",ylab="",pch=20,bty="n")
abline(siteLM)
title("f)", adj = 0)
sm <- summary(siteLM)
text(-6.5,0.004,paste('p-value:',round(sm$coefficients[2,4],digits=3)),pos=4)
text(-6.5,0.0032,parse(text=paste0("R^2",":",round(sm$r.squared,digits=3))),pos=4)

dev.off()

beta.site$site = reorder(beta.site$site,beta.site$day50)
beta.site$siteFullName <- site_full_names[match(beta.site$site,names(site_full_names))]

jpeg(file=paste0(figureDirectory,"GAM_siteCRPS.jpeg"),width = 7, height = 4, units = "in",res=1000)
ggplot(beta.site) + 
  xlab("Site")+
  ggthemes::theme_base()+
  geom_bar( aes(x=fct_reorder(siteFullName,day50), y=Estimate), stat="identity", fill="grey31", alpha=0.5) +
  geom_errorbar( aes(x=siteFullName, ymin=Estimate-1.96*SE, ymax=Estimate+1.96*SE), width=0.4, colour="black", alpha=0.9, size=1.3) +
  coord_flip() + ylab("CRPS") +
  theme(panel.background = element_blank(),axis.line=element_line(),panel.border = element_blank(),
                                                             plot.background=element_blank())
dev.off()

```

#Figure S7: Site by team interactions
```{r}
alpha = as.data.frame(summary(fit2i)$p.table) %>% mutate(lab = rownames(.)) %>% separate(lab,c("site","team"),sep = ":")  ## grab summary table
#recode primary effects
noteam <- which(is.na(alpha$team) & grepl("site",alpha$site))
nosite <- which(is.na(alpha$team) & grepl("team",alpha$site))
alpha$team[nosite] <- alpha$site[nosite]
alpha$site[c(1,nosite)] <- "BART"
alpha$team[c(1,noteam)] <- "DOY_Mean"
alpha$site <- gsub("siteID","",alpha$site)
alpha$team <- gsub("team","",alpha$team)
colnames(alpha)[2] <- "SE"
# add intercept to site effect
alpha$Estimate[2:8] = alpha$Estimate[2:8] + alpha$Estimate[1] ## rescale mean
alpha$SE[2:8] = sqrt(alpha$SE[2:8]^2 + alpha$SE[1]^2 + 2*vcov(fit2i)[2:8,1]) ## rescale SE
# add site means to all other terms
aS <- alpha[1:8,] %>%  dplyr::select(Estimate:SE,site) %>% rename(Smu = Estimate,Sse=SE) ## pull out site effects
alpha = alpha %>% left_join(aS,by="site") %>%  ## add site effects as column
  mutate(Smu=if_else(team=="DOY_Mean",0,Smu),Sse=if_else(team=="DOY_Mean",0,Sse)) %>%  ## set default case to 0
  mutate(Estimate = Estimate + Smu,SE = sqrt(SE^2 + Sse^2)) ##update stats
## add team effect (ref site = BART) to all other terms
aT <- alpha %>% filter(site == "BART") %>% rename(Tmu = Estimate,Tse=SE) %>%  
  mutate(Tmu=if_else(team=="DOY_Mean",0,Tmu),Tse=if_else(team=="DOY_Mean",0,Tse)) %>% ## intercept
  select(Tmu:Tse,team) 
alpha = alpha %>% left_join(aT,by="team") %>%  ## add site effects as column
  mutate(Tmu=if_else(site=="BART",0,Tmu),Tse=if_else(site=="BART",0,Tse)) %>%  ## set default case to 0
  mutate(Estimate = Estimate + Tmu,SE = sqrt(SE^2 + Tse^2)) ##update stats
colnames(alpha)[4] <- "pval"
alpha = alpha %>% mutate(sig = as.numeric(pval < 0.05)) ## add significance test for visualization
alpha$Estimate[alpha$Estimate<0] = 0 ## sanity check

## visualize
jpeg(file=paste0(figureDirectory,"GAM_interactions.jpeg"),width = 6, height = 8, units = "in",res=1000)
ggplot(alpha) + aes(x=team, y=Estimate,fill=site) +
  geom_bar(stat="identity",  alpha=alpha$sig+0.3, position = "dodge") + scale_alpha(range = c(0.1, 0.9)) +
#  geom_errorbar( aes(x=team, ymin=Estimate-1.96*SE, ymax=Estimate+1.96*SE), width=0.4, colour="orange", alpha=0.9, position="dodge") +
  coord_flip() + ylab("CRPS") +
  xlab("Model")+
  theme_base() +
  theme(panel.background = element_blank(),axis.line=element_line(),panel.border = element_blank(),plot.background=element_blank(),legend.position = c(0.75,0.4))+
    ggplot2::scale_fill_manual(values = siteColors)
dev.off()

```

# Lead time plots (not included)
```{r}

hnew <- 1:35
crps_horiz <- predict(fit2,data.frame(horizon=hnew,siteID="HARV",team="Persistence",phenoDate=0))
plot(hnew,crps_horiz,xlab="Horizon",ylab="predicted CRPS",type="l",lwd=3)

## phenoDate
pDnew2 <- -80:40
crps_pD <- predict(fit2,data.frame(horizon=1,siteID="HARV",team="Persistence",phenoDate=pDnew2))
plot(pDnew2,crps_pD,xlab="Days from 15%",ylab="predicted CRPS",lwd=3,type='l')
abline(v=0,lty=2)
print(paste("We are worst when forecasting on:",pDnew2[which.max(crps_pD)],"days after 15% green-up"))

crps_pD_time <- predict(fit2_time,data.frame(horizon=1,siteID="HARV",team="Persistence",phenoDate_time=pDnew2))
plot(pDnew2,crps_pD_time,xlab="Days from 15%",ylab="predicted CRPS",lwd=3,type='l')
abline(v=0,lty=2)
print(paste("We are worst at forecasting:",pDnew2[which.max(crps_pD_time)],"days after 15% green-up"))

plotPredictability <- function(trans){
  matchSite <- match(gcc_forecast_subset$siteID, allTransitions$siteID)
  if(trans==0.50){
    gcc_forecast_subset4 <- gcc_forecast_subset %>% 
      mutate(day85 = allTransitions$day85[matchSite],
             day50 = allTransitions$day50[matchSite],
             day15 = allTransitions$day15[matchSite],
             phenoDate = lubridate::yday(time) - day50)
  }else if(trans==0.15){
    gcc_forecast_subset4 <- gcc_forecast_subset %>% 
      mutate(day85 = allTransitions$day85[matchSite],
             day50 = allTransitions$day50[matchSite],
             day15 = allTransitions$day15[matchSite],
             phenoDate = lubridate::yday(time) - day15)
  }else if(trans==0.85){
    gcc_forecast_subset4 <- gcc_forecast_subset %>% 
      mutate(day85 = allTransitions$day85[matchSite],
             day50 = allTransitions$day50[matchSite],
             day15 = allTransitions$day15[matchSite],
             phenoDate = lubridate::yday(time) - day85)
  }
  fit <- gam(crps ~ siteID + s(horizon) + team + s(phenoDate), 
             data = gcc_forecast_subset4,
             method="REML")
  
  pDnew <- -80:40
  crps_pD <- predict(fit,data.frame(horizon=1,siteID="HARV",team="Persistence",phenoDate=pDnew))
  plot(pDnew,crps_pD,xlab=paste0("Days from ",trans*100,"% Greenup"),ylab="predicted CRPS",ylim=c(0.005,0.03),pch=20)
  abline(v=0,lty=2,col="gray")
  print(pDnew[which.max(crps_pD)])
  abline(v=pDnew[which.max(crps_pD)],col="red")
}
par(mfrow=c(1,3))
plotPredictability(trans=0.15)
plotPredictability(trans=0.50)
plotPredictability(trans=0.85)
```

*GAM: Horizon and phenoDate by team*
fits
```{r, echo=FALSE}
## FIT HORIZON AN PHENODATE BY TEAM
# Ran overnight but never finished
#fit5 <- mgcv::gam(crps ~ siteID + s(horizon,by=as.factor(team)) + team + s(phenoDate,by=as.factor(team)),
#            data = gcc_forecast_subset2,
#            method="REML")
if(!file.exists("fit5.RDS")){
  fit5 <- list()
  for(i in seq_along(teams)){
    print(i)
    tm <- teams[i]
    if(tm=="DOY_Mean"){
      tm <- " DOY_Mean"
    }
    gcc_team <- gcc_forecast_subset2 %>% filter(team == tm)
    fit5[[i]] <- try(mgcv::gam(crps ~ s(horizon) + s(phenoDate),
                               data = gcc_team,
                               method="REML"))
  }
  names(fit5) <- teams
  lapply(fit5,summary)
  saveRDS(fit5,file="fit5.RDS")
}else {
  fit5 <- readRDS("fit5.RDS")
}


## "all model" equivalent for comparision
fit5a <- mgcv::gam(crps ~ s(horizon) + s(phenoDate),
            data = gcc_forecast_subset2,
            method="REML")

```

plots not included, but some variables need to be created to use later
```{r, echo=FALSE}
## horizon plot
hnew <- 1:35
crps_horiz5 <- list()
for(i in seq_along(teams)){
  if("try-error" %in% class(fit5[[i]])){
    crps_horiz5[[i]] <- NA
  } else {
    crps_horiz5[[i]] <- predict(fit5[[i]],data.frame(horizon=hnew,phenoDate=0))
  }
}
crps_horiz5a <- predict(fit5a,data.frame(horizon=hnew,phenoDate=0))
h5range = c(min(sapply(crps_horiz5,min),na.rm=TRUE),
            max(sapply(crps_horiz5,max),na.rm=TRUE))
#cls <- paletteMartin[c(2,1,3:15)]

toPlot5 <- c()
j = 0
plot(hnew,crps_horiz5a,xlab="Lead Time",ylab="predicted CRPS",
     ylim=h5range,type='l',lwd=1,lty=2)
for(i in seq_along(teams)){
  if(!("try-error" %in% class(fit5[[i]]))){
    j = j+1; toPlot5 = c(toPlot5,i)
    lines(hnew,crps_horiz5[[i]],col=cls[i],lwd=3)
  }
}
legend("topleft",col=cls[toPlot5],lwd = 2, lty=1, legend = teams[toPlot5],cex=0.5,ncol=3)

#HORIZON: Relative error
plot(hnew,crps_horiz5a/crps_horiz5a[1],xlab="Lead Time",ylab="predicted CRPS",
     ylim=c(0.75,2),type='l',lwd=1,lty=2)
for(i in seq_along(toPlot5)){
  y = crps_horiz5[[toPlot5[i]]]
  lines(hnew,y/y[1],col=cls[toPlot5[i]],lwd=3)
}
legend("topleft",col=cls[toPlot5],lwd = 2, lty=1, legend = teams[toPlot5],cex=0.5,ncol=3,bty="n")

#HORIZON: delCRPS (Include)
plot(hnew,crps_horiz5a-crps_horiz5a[1],xlab="Lead Time",ylab="delCRPS",
     ylim=c(-0.005,0.025),type='l',lwd=1,lty=2,bty="n")
for(i in seq_along(toPlot5)){
  y = crps_horiz5[[toPlot5[i]]]
  lines(hnew,y-y[1],col=cls[toPlot5[i]],lwd=3)
}
legend("topleft",col=cls[toPlot5],lwd = 2, lty=1, legend = teams[toPlot5],cex=0.5,ncol=3, bty="n")

## phenoDate plot

pD_team <- gcc_forecast_subset2 %>%  group_by(team) %>%
  summarise(min = min(phenoDate,na.rm = TRUE), max=max(phenoDate,na.rm = TRUE))
pD_team$team[pD_team$team==" DOY_Mean"] <- "DOY_Mean"
crps_pD5 <- list()
pDnew <- list()
for(i in toPlot5){
    pDnew[[i]] <- pD_team$min[i]:pD_team$max[i]
    crps_pD5[[i]] <- predict(fit5[[i]],data.frame(horizon=1,phenoDate=pDnew[[i]]))
}
crps_pD5a <- predict(fit5a,data.frame(horizon=1,phenoDate=-80:40))
#p5range = c(min(sapply(crps_pD5,min),na.rm=TRUE),
#            max(sapply(crps_pD5,max),na.rm=TRUE))

plot(-80:40,crps_pD5a,xlab="Days from 15%",ylab="predicted CRPS",
     ylim=h5range,type='l',lwd=1,lty=2,xlim=c(-80,40))
for(i in seq_along(toPlot5)){
    lines(pDnew[[toPlot5[i]]],crps_pD5[[toPlot5[i]]],col=cls[toPlot5[i]],lwd=3)
}
abline(v=0,lty=2)
legend("topleft",col=cls[toPlot5],lwd = 2, lty=1, legend = teams[toPlot5],cex=0.5,ncol=3,bty="n")

## find max
pD5max = rep(NA,length(teams))
for(i in toPlot5){
  pD5max[i] = pDnew[[i]][which.max(crps_pD5[[i]])]
}
pD5max[pD5max>40] = NA ## remove outlier
hist(pD5max,breaks = 6)
abline(v=mean(pD5max,na.rm = TRUE))
mean(pD5max,na.rm = TRUE)
```

*GAM: Horizon and phenodate by model class*
fit
```{r,echo=FALSE}
# didn't converge
#fit4 <- mgcv::gam(crps ~ siteID + class + s(horizon,by=as.factor(class)) + team + s(phenoDate),
#            data = gcc_forecast_subset2,
#            method="REML")
#summary(fit4)

if(!file.exists("fit4.RDS")){
  fit4 <- list()
  for(i in seq_along(mtype)){
    print(i)
    gcc_mtype <- gcc_forecast_subset2 %>% filter(class == mtype[i])
    fit4[[i]] <- try(mgcv::gam(crps ~ s(horizon) + s(phenoDate),
                               data = gcc_mtype,
                               method="REML"))
  }
  names(fit4) <- mtype
  saveRDS(fit4,file="fit4.RDS")
} else {
  fit4 <- readRDS("fit4.RDS")
}
names(fit4) <- mtype
lapply(fit4,summary)

```

plots (extra and not included, but some of the variables need to be made)
```{r,echo=FALSE}
#mname = c("dynamic","persist","clim","covariate","static")
mname <- names(mtype)
mname[mname=="clim"] <- "DOY_Mean"

## horizon plot
hnew <- 1:35
crps_horiz4 <- list()
for(i in seq_along(mtype)){
    crps_horiz4[[i]] <- predict(fit4[[i]],data.frame(horizon=hnew,phenoDate=0))
}
h4range = c(min(sapply(crps_horiz4,min),na.rm=TRUE),
            max(sapply(crps_horiz4,max),na.rm=TRUE))
#cls <- paletteMartin

plot(hnew,crps_horiz5a,xlab="Lead Time",ylab="CRPS",
     ylim=h4range,type='l',lwd=1,lty=2,bty="n")
for(i in seq_along(mtype)){
    lines(hnew,crps_horiz4[[i]],col=classCls[i],lwd=3)
}
legend("topleft",col=classCls,lwd = 3, lty=1, legend = mname,cex=0.75,ncol=3,bty="n")

#HORIZON: Relative error 
plot(hnew,crps_horiz5a/crps_horiz5a[1],xlab="Lead Time",ylab="relative CRPS",
     ylim=c(0.75,2),type='l',lwd=3,lty=2,bty="n")
for(i in seq_along(mtype)){
  if(mtype[i] == "NANA") next
  y = crps_horiz4[[i]]
  lines(hnew,y/y[1],col=classCls[i],lwd=3)
}
legend("topleft",col=classCls,lwd = 3, lty=1, legend = mname,cex=0.75,ncol=3,bty="n")

#HORIZON: delCRPS (include)
plot(hnew,crps_horiz5a-crps_horiz5a[1],xlab="Lead Time",ylab="delCRPS",
     ylim=c(-0.005,0.025),type='l',lwd=3,lty=2,bty="n")
for(i in seq_along(mtype)){
  y = crps_horiz4[[i]]
  lines(hnew,y-y[1],col=classCls[i],lwd=3)
}
legend("topleft",col=classCls,lwd = 3, lty=1, legend = mname,cex=0.75,ncol=3,bty="n")

## phenoDate plot 
pD_mtype <- gcc_forecast_subset2 %>%  group_by(class) %>%
  summarise(min = min(phenoDate,na.rm = TRUE), max=max(phenoDate,na.rm = TRUE))
pD_mtype$min[pD_mtype$min < -80] = -80 ## standardize start date
crps_pD4 <- list()
pDnew4 <- list()
for(i in seq_along(mtype)){
    pDnew4[[i]] <- pD_mtype$min[i]:pD_mtype$max[i]
    crps_pD4[[i]] <- predict(fit4[[i]],data.frame(horizon=1,phenoDate=pDnew4[[i]]))
}

plot(-80:40,crps_pD5a,xlab="Days from 15%",ylab="predicted CRPS",type='l',lwd=1,lty=2,xlim=c(-80,40),bty="n",ylim=c(-0.02,0.06)) #Exclude
for(i in seq_along(mtype)){
    lines(pDnew4[[i]],crps_pD4[[i]],col=classCls[i],lwd=3)
}
abline(v=0,lty=2)
legend("topleft",col=cls[seq_along(mtype)],lwd = 2, lty=1, legend = mname,cex=1,ncol=3,bty="n")

# phenodate: delCRPS (include)
plot(-80:40,crps_pD5a-crps_pD5a[1],xlab="Days from 15%",ylab="delCRPS",
     ylim=h5range,type='l',lwd=1,lty=2,xlim=c(-80,40),bty="n")
for(i in seq_along(mtype)){
    y = crps_pD4[[i]]
    lines(pDnew4[[i]],y-y[1],col=classCls[i],lwd=3)
}
abline(v=0,lty=2)
legend("topleft",col=classCls,lwd = 3, lty=1, legend = mname,cex=1,ncol=3,bty="n")


```

#Figure 4: GAM response surfaces with lead time
```{r}
#Note: Need to edit legend outside of R to get dotted line to show
jpeg(file=paste0(figureDirectory,"GAM_responseSurfaces.jpeg"),width = 8, height = 5, units = "in",res=1000)
layout(matrix(c(1,2,3,3),ncol=2,byrow=FALSE))
par(mai=c(0.8,0.8,0.3,0.5))

# ## OVERALL
# plot(hnew,crps_horiz,xlab="",ylab="CRPS",type="l",lwd=3,bty="n",xaxt="n",main="")
# title("a)", adj = 0)
# axis(1, at=seq(0,35,5),labels=rep("",8))

## MODEL TYPE: CRPS
plot(-1*hnew,crps_horiz5a,xlab="",ylab="CRPS",
     ylim=c(0,0.08),type='l',lwd=3,lty=1,bty="n",xaxt="n",main="")
title("a)", adj = 0)
for(i in seq_along(mtype)){
    lines(-1*hnew,crps_horiz4[[i]],col=classCls[i],lwd=3)
  print(mean(crps_horiz4[[i]]))
}
axis(1, at=seq(-35,0,5),labels=rep("",8))
legend("topleft",col=c("black",classCls,"black"),lwd = 3, lty=rep(1,6), legend = c("all",mname),cex=0.85,ncol=3,bty="n",text.width = 6,x.intersp=0.3)

#MODEL TYPE: delCRPS
plot(-1*hnew,crps_horiz5a-crps_horiz5a[1],ylab=expression("CRPS - CRPS"["time=0"]),xlab="Lead Time (Days)", ylim=c(-0.005,0.035),type='l',lwd=3,lty=1,bty="n",main="")
title("b)", adj = 0)
abline(h=0,lwd=4,lty=2)
for(i in seq_along(mtype)){
  y = crps_horiz4[[i]]
  lines(-1*hnew,y-y[1],col=classCls[i],lwd=3)
}
legend("topright",col=c("black",classCls,"black"),lwd = 3, lty=c(rep(1,6),1), legend = c("all",mname,"=0"),cex=0.85,ncol=3,bty="n",text.width = 6,x.intersp=0.3)
# legend("topleft",col=cls[seq_along(mtype)],lwd = 3, lty=1, legend = mname,cex=0.75,ncol=3)

#MODEL: delCRPS
plot(-1*hnew,crps_horiz5a-crps_horiz5a[1],xlab="Lead Time (Days)",ylab=expression("CRPS - CRPS"["time=0"]),
     ylim=c(-0.015,0.045),type='l',lwd=3,lty=1,bty="n",main="")
title("c)", adj = 0)
abline(h=0,lwd=4,lty=2)
for(i in seq_along(teams)[-c(4,11)]){ #Note 4 and 11 are included because there were not enough submissions to fit the GAMs for the individaul models 
  y = crps_horiz5[[i]]
  lines(-1*hnew,y-y[1],col=cls[i],lwd=3)
}
legend("topleft",col=c("black",cls[-c(4,11)],"black"),lwd = 2, lty=c(rep(1,length(teams[-c(4,11)]),1,2)), legend = c("all",teams[-c(4,11)],"=0"),cex=0.85,ncol=2,bty="n",text.width = 12)
dev.off()
```

## Figure 6: Changes in CRPS based on date of submission of forecasts
```{r}
jpeg(file=paste0(figureDirectory,"GAM_changedInCRPS.jpeg"),width = 6, height = 6, units = "in",res=1000)
layout(matrix(c(1,1,2,2,2),ncol=1,byrow=TRUE))
par(mai=c(0.7,0.8,0.3,1))
## phenoDate by CLASS
pD_mtype <- gcc_forecast_subset2 %>%  group_by(class) %>%
  summarise(min = min(phenoDate,na.rm = TRUE), max=max(phenoDate,na.rm = TRUE))
pD_mtype$min[pD_mtype$min < -80] = -80 ## standardize start date
crps_pD4 <- list()
pDnew4 <- list()
for(i in seq_along(mtype)){
    pDnew4[[i]] <- pD_mtype$min[i]:pD_mtype$max[i]
    crps_pD4[[i]] <- predict(fit4[[i]],data.frame(horizon=1,phenoDate=pDnew4[[i]]))
}
names(fit4)
sapply(crps_pD4,which.max) + sapply(pDnew4,min)
which.max(crps_pD5a)-80

plot(-80:40,crps_pD5a-crps_pD5a[1],xlab="",ylab=expression("CRPS - CRPS"["time=0"]),
     type='l',lwd=5,xlim=c(-40,40),ylim=c(-0.0012,0.07),bty="n",main="",xaxt="n")
title("a)", adj = 0)
axis(1, at=seq(-80,40,20),labels=rep("",7))
for(i in seq_along(mtype)){
    y = crps_pD4[[i]]
    lines(pDnew4[[i]],y-y[1],col=classCls[i],lwd=3)
}
abline(v=0,lty=2,lwd=1)
legend("topleft",col=c(1,classCls[seq_along(mtype)]),lwd = 3, lty=1, 
       legend = c("all",mname[1:4],"DOY_Mean"),cex=1,ncol=3,bty="n")

#By Model
crps_pD5 <- list()
pDnew <- list()
for(i in toPlot5){
    j = which(pD_team$team == names(fit5)[i])
    pDnew[[i]] <- pD_team$min[j]:pD_team$max[j]
    crps_pD5[[i]] <- predict(fit5[[i]],data.frame(horizon=1,phenoDate=pDnew[[i]]))
}
crps_pD5a <- predict(fit5a,data.frame(horizon=1,phenoDate=-80:40))
plot(-80:40,crps_pD5a,ylab="CRPS",
     ylim=c(-0.0012,0.08),type='n',lwd=5,xlim=c(-40,40),bty="n",main="",xlab="Days After 15% Greenup of Submission Date")
title("b)", adj = 0)

for(i in seq_along(toPlot5)){
    lines(pDnew[[toPlot5[i]]],crps_pD5[[toPlot5[i]]],col=teamCls[toPlot5[i]],lwd=3)
}
lines(-80:40,crps_pD5a,lwd=5) ## overall model on top
abline(v=0,lty=2)
legend("topleft",col=c(1,teamCls[toPlot5]),lwd = 2, lty=1, 
       legend = c("all",teams[toPlot5]),cex=1,ncol=3,bty="n")

dev.off()
```

#Figure 5: Fit the model where the forecasted days relative to 15% greenup is a predictor and look at how it differs between sites
```{r}
if(!file.exists("fit_time_site.RDS")){
  fit_time_site <- list()
  for(i in seq_along(site_names)){
    print(i)
    gcc_mtype <- gcc_forecast_subset2 %>% filter(siteID == site_names[i])
    fit_time_site[[i]] <- try(mgcv::gam(crps ~ s(horizon) + s(phenoDate_time),
                               data = gcc_mtype,
                               method="REML"))
    saveRDS(fit_time_site,file="fit_time_site.RDS")
  }
}else {
  fit_time_site <- readRDS("fit_time_site.RDS")
}
names(fit_time_site) <- site_names
lapply(fit_time_site,summary)

pD_mtype <- gcc_forecast_subset2 %>%  group_by(siteID) %>%
  summarise(min = min(phenoDate_time,na.rm = TRUE), max=max(phenoDate_time,na.rm = TRUE))
pD_mtype$min[pD_mtype$min < -80] = -80 ## standardize start date
crps_pD4 <- list()
pDnew4 <- list()

fit5a_time <- mgcv::gam(crps ~ s(horizon) + s(phenoDate_time),
            data = gcc_forecast_subset2,
            method="REML")
crps_pD5a_time <- predict(fit5a_time,data.frame(horizon=1,phenoDate_time=-80:40))

for(i in seq_along(site_names)){
    pDnew4[[i]] <- pD_mtype$min[i]:pD_mtype$max[i]
    crps_pD4[[i]] <- predict(fit_time_site[[i]],data.frame(horizon=1,phenoDate_time=pDnew4[[i]]))
}
sapply(crps_pD4,which.max) + sapply(pDnew4,min)
#which.max(crps_pD5a)-80

#By Site

jpeg(file=paste0(figureDirectory,"GAM_time_bySite.jpeg"),width = 8, height = 3, units = "in",res=1000)
layout(matrix(c(1,1,2),ncol=3,byrow=FALSE))
par(mai=c(0.8,0.8,0.3,0.1))
plot(-80:40,crps_pD5a_time,xlab="Days After 15% Greenup of Forecasted Date",ylab="CRPS",
     type='l',lwd=5,xlim=c(-20,40),ylim=c(0,0.055),bty="n",main="")
title("a)", adj = 0)
maxCRPS <- numeric()
greenupLengths <- numeric()
for(i in seq_along(site_names)){
    y = crps_pD4[[i]]
    lines(pDnew4[[i]],y,col=siteColors[i],lwd=3)
    maxCRPS <- c(maxCRPS,max(y))
    greenupLengths <- c(greenupLengths,
                        (allTransitionDys$day85[allTransitionDys$siteID==site_names[i]]-allTransitionDys$day15[allTransitionDys$siteID==site_names[i]]))
    
    allTransitionDys$day85[allTransitionDys$siteID==site_names[i]]-
      allTransitionDys$day15[allTransitionDys$siteID==site_names[i]]
    if(i==1){
          abline(v=(allTransitionDys$day85[allTransitionDys$siteID==site_names[i]]-allTransitionDys$day15[allTransitionDys$siteID==site_names[i]]),lty=2,lwd=3,col=siteColors[i])
    }else{
    abline(v=(allTransitionDys$day85[allTransitionDys$siteID==site_names[i]]-allTransitionDys$day15[allTransitionDys$siteID==site_names[i]]),lty=2,lwd=2,col=siteColors[i])
    }
}

legend("topleft",col=c(1,siteColors[order(allTransitionDys$day85 - allTransitionDys$day15)]),lwd = 3, lty=1, 
       legend = c("all",site_full_names[order(allTransitionDys$day85 - allTransitionDys$day15)]),cex=1,ncol=1,bty="n",y.intersp=1,x.intersp=0.3,
       text.width = 12)

mdl <- lm(maxCRPS~greenupLengths)
summary(mdl)
plot(greenupLengths,maxCRPS,pch=20,main="",xlab="Greenup Length (Days)",ylab="Site Max CRPS",bty="n",cex=2,col=siteColors)
title("b)", adj = 0)
abline(mdl,lwd=3)
dev.off()

```